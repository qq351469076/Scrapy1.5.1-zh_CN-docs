<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="孔祥旭 qq:351469076 微信:kxx351469076">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>核心API - Scrapy 1.5.1 中文文档</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u6838\u5fc3API";
    var mkdocs_page_input_path = "5. Scrapy\u6269\u5c55\\05-api.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Scrapy 1.5.1 中文文档</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">1. 第一步</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../1. 第一步/01-index/">Scrapy 1.5 中文文档</a>
                </li>
                <li class="">
                    
    <a class="" href="../../1. 第一步/02-overview/">一眼了解Scrapy</a>
                </li>
                <li class="">
                    
    <a class="" href="../../1. 第一步/03-install/">安装指导</a>
                </li>
                <li class="">
                    
    <a class="" href="../../1. 第一步/04-scrapy tutorial/">Scrapy 教程</a>
                </li>
                <li class="">
                    
    <a class="" href="../../1. 第一步/05-examples/">例子</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">2. 基本概念</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../2. 基本概念/06-command_line_tool/">Command line tool(命令行工具)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/07-spiders/">Spiders(自定义爬虫类)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/08-selctor/">Selector(选择器)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/09-items/">Items(模型)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/10-itemloaders/">Item Loaders(Item加载器)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/11-scrapy_shell/">Scrapy shell(Scrapy终端)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/12-item_pipeline/">Item Pipeline(模组管道)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/13-feed_exports/">Feed exports(导出各种格式文件)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/14-requests_response/">Requests和Responses</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/15-extractors/">Link Extractors(链接提取器)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../2. 基本概念/16-settings/">Settings(设置)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">3. 内置服务</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../3. 内置服务/17-logging/">Logging(日志记录)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../3. 内置服务/18-stats-collection/">Stats Collection(状态收集)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../3. 内置服务/19-send-email/">Sending e-mail(发送一个邮件)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../3. 内置服务/20-telnet-console/">Telnet Console(Telnet控制台)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../3. 内置服务/21-web-service/">Web Service(Web服务)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">4. 解决具体问题</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/01-常见问题解答/">常见问题解答</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/02-debugind-spider/">Debugging Spiders(调试Spiders)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/03-Spiders Contracts/">Spiders Contracts</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/04-common-practices/">Common Practices(常用实践)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/05-broad-crawls/">Broad Crawls</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/06-use-firefox-scraping/">使用Firefox进行抓取(没写)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/07-use-firbug-scraping/">使用Firebug进行抓取(没写)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/08-debugging-memory/">调试内存泄漏</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/09-down-file-image/">下载并处理文件和图像</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/10-deploying-spider/">部署Spider</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/11-auto-throttle-extension/">AutoThrottle extension(自动节流扩展)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/12-Benchmark/">基准测试</a>
                </li>
                <li class="">
                    
    <a class="" href="../../4. 解决具体问题/13-pausing-resuming-crawls/">作业: 暂停和恢复爬虫</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">5. Scrapy扩展</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../01-Architecture-overview/">架构概述</a>
                </li>
                <li class="">
                    
    <a class="" href="../02-Downloader-Middleware/">Downloader Middleware(下载器中间件)</a>
                </li>
                <li class="">
                    
    <a class="" href="../03-spider-middleware/">Spider Middleware</a>
                </li>
                <li class="">
                    
    <a class="" href="../04-Extensions/">Extensions(扩展)</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">核心API</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#api">核心API</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#crawler-api">Crawler API</a></li>
        
            <li><a class="toctree-l4" href="#settings-api">Settings API</a></li>
        
            <li><a class="toctree-l4" href="#spiderloader-api">SpiderLoader API</a></li>
        
            <li><a class="toctree-l4" href="#signals-api">Signals API(信号)</a></li>
        
            <li><a class="toctree-l4" href="#stats-collector-api">Stats Collector API</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../06-signals/">Signals(信号)</a>
                </li>
                <li class="">
                    
    <a class="" href="../07-exporters/">Item Exporters(Items导出器)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">6. 其他的</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../6. 其他的/01-news/">发行说明</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Scrapy 1.5.1 中文文档</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>5. Scrapy扩展 &raquo;</li>
        
      
    
    <li>核心API</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="api">核心API</h1>
<p>版本0.15添加此功能</p>
<p>本节记录了Scrapy核心API，它是为extensions和middlewares的开发人员准备的。</p>
<h2 id="crawler-api">Crawler API</h2>
<p>Scrapy API的主要入口点是<a href="#">Crawler</a>对象，通过<code>from_crawler</code>类方法传递给extensions。这个对象提供了对所有Scrapy核心组件的访问，这是extensions访问它们并将其功能连接到Scrapy的唯一方法。</p>
<p>Extension Manager负责加载和跟踪已安装的extensions，它通过<a href="#">EXTENSIONS</a> setting进行配置，<a href="#">EXTENSIONS</a> setting包含所有可用extensions的字典和它们的顺序，类似于您<a href="#">配置downloader middlewares</a>的方式。</p>
<h4 id="scrapycrawlercrawlerspidercls-settings-class">scrapy.crawler.Crawler(spidercls, settings)   这是一个类(class)</h4>
<p>Crawler对象必须用<a href="#">scrapy.spiders.Spider</a>子类和<a href="#">scrapy.settings.Settings</a>实例化。</p>
<p><code>settings</code></p>
<blockquote>
<p>crawler的settings manager。</p>
<p>extensions和middlewares使用它来访问这个crawler的Scrapy settings。</p>
<p>有关Scrapy settings的介绍，请参见<a href="#">Settings</a>。</p>
<p>有关API，请参阅<a href="#">Settings</a>类。</p>
</blockquote>
<p><code>signals</code></p>
<blockquote>
<p>crawler的signals manager。</p>
<p>extensions和middlewares使用它将自己连接到Scrapy功能中。</p>
</blockquote>
<p><code>stats</code></p>
<blockquote>
<p>crawler的stats collector。</p>
<p>这是由extensions和middlewares用来记录他们行为的stats，或者其他extensions收集的access stats。</p>
<p>有关stats collection的介绍，请参阅<a href="#">Stats Collection</a>。</p>
<p>有关API，请参见<a href="#">StatsCollector</a>类。</p>
</blockquote>
<p><code>extensions</code></p>
<blockquote>
<p>跟踪已启用extensions的extension manager。</p>
<p>大多数extensions不需要访问这个属性。</p>
<p>有关extensions的介绍和Scrapy上的可用extensions列表，请参阅<a href="#">Extensions</a>。</p>
</blockquote>
<p><code>engine</code></p>
<blockquote>
<p>执行引擎，它协调scheduler、downloader和spiders之间的核心爬行逻辑。</p>
<p>一些extension可能想要访问Scrapy engine，以检查或修改downloader和scheduler的行为，尽管这是一种高级用法，而且这个API还不稳定。</p>
</blockquote>
<p><code>spider</code></p>
<blockquote>
<p>目前正在抓取的spider。这是在构造crawler时提供的spider类的实例，它是在<a href="#">crawler()</a>方法中给出的参数之后创建的。</p>
</blockquote>
<p><code>crawl(*args, **kwargs)</code></p>
<blockquote>
<p>启动crawler时，使用给定的<em>arg</em>和<em>kwargs</em>参数实例化它的spider类，同时启动执行引擎。</p>
<p>返回当完成抓取时触发的延迟</p>
</blockquote>
<h4 id="scrapycrawlercrawlerrunnersettingsnone-class">scrapy.crawler.CrawlerRunner(settings=None)   这是一个类(class)</h4>
<p>这是一个方便的助手类，用于跟踪、管理和运行已经设置好的Twisted <a href="https://twistedmatrix.com/documents/current/core/howto/reactor-basics.html">reactor</a>中的crawlers。</p>
<p>CrawlerRunner对象必须用设置对象实例化。</p>
<p>除非编写手工处理抓取过程的脚本，否则不应该需要这个类(因为Scrapy有使用它的责任)。有关示例，请参阅<a href="#">从脚本中的运行Scrapy</a>。</p>
<p><code>crawl(crawler_or_spidercls, *args, **kwargs)</code></p>
<blockquote>
<p>使用提供的参数运行crawler。</p>
<p>它将调用给定的Crawler的<a href="#">crawl()</a>方法，同时跟踪它，以便稍后可以停止它。</p>
<p>如果<em>crawler_or_spidercls</em>不是一个<a href="#">Crawler</a>实例，这个方法将尝试创建一个使用这个参数的spider类。</p>
<p>返回当完成抓取时触发的延迟</p>
<p>参数:</p>
<blockquote>
<ul>
<li><strong>crawler_or_spidercls</strong> (<a href="#">Crawler</a>实例, <a href="#">Spider</a>子类或字符串) – 已经在项目中创建了crawler，或者一个spider类或spider的名称来创建它</li>
<li><strong>args</strong> (列表) – 初始化spider的参数</li>
<li><strong>kwargs</strong> (字典) – 初始化spider的关键字参数</li>
</ul>
</blockquote>
</blockquote>
<p><code>crawlers</code></p>
<blockquote>
<p>由<a href="#">crawl()</a>开始并由该类管理的一组<a href="#">crawlers</a>。</p>
</blockquote>
<p><code>create_crawler(crawler_or_spidercls)</code></p>
<blockquote>
<p>返回<a href="#">Crawler</a>对象。</p>
<ul>
<li>如果<em>crawler_or_spidercls</em>是一个Crawler，它将按原样返回。</li>
<li>如果<em>crawler_or_spidercls</em>是Spider子类，则为它构造一个新的Crawler。</li>
<li>如果<em>crawler_or_spidercls</em>是一个字符串，这个函数会在Scrapy项目中找到一个具有这个名称的spider(使用spider loader)，然后为它创建一个Crawler实例。</li>
</ul>
</blockquote>
<p><code>join()</code></p>
<blockquote>
<p>返回一个延迟，当所有托管<a href="#">crawlers</a>完成执行时触发。</p>
</blockquote>
<p><code>stop()</code></p>
<blockquote>
<p>同时停止所有爬虫作业。
返回一个延迟，当它们都结束时将被触发。</p>
</blockquote>
<h4 id="scrapycrawlercrawlerprocesssettingsnone-install_root_handlertrue-class">scrapy.crawler.CrawlerProcess(settings=None, install_root_handler=True)   这是一个类(class)</h4>
<blockquote>
<p>基础: <a href="#">scrapy.crawler.CrawlerRunner</a></p>
<p>在一个进程中同时运行多个Scrapy crawler的类。</p>
<p>这个类扩展了<a href="#">CrawlerRunner</a>，添加了对启动Twisted <a href="https://twistedmatrix.com/documents/current/core/howto/reactor-basics.html">reactor</a>和处理关闭信号的支持，比如键盘中断命令Ctrl-C。它还配置最高级别的logging。</p>
<p>如果您的应用程序中没有运行另一个Twisted <a href="https://twistedmatrix.com/documents/current/core/howto/reactor-basics.html">reactor</a>，那么这个实用程序应该比<a href="#">CrawlerRunner</a>更适合使用。</p>
<p>CrawlerProcess对象必须用<a href="#">Settings</a>对象实例化。</p>
<blockquote>
<p>参数: </p>
<ul>
<li>install_root_handler – 是否安装root logging handler(默认:True)</li>
</ul>
</blockquote>
<p>除非编写手工处理爬行过程的脚本，否则不应该需要这个类(因为Scrapy有使用它的责任)。有关示例，请参阅<a href="#">从脚本中的运行Scrapy</a>。</p>
</blockquote>
<p><code>crawl(crawler_or_spidercls, *args, **kwargs)</code></p>
<blockquote>
<p>使用提供的参数运行crawler。</p>
<p>它将调用给定的Crawler的<a href="#">crawl()</a>方法，同时跟踪它，以便稍后可以停止它。</p>
<p>如果<em>crawler_or_spidercls</em>不是一个<a href="#">Crawler</a>实例，这个方法将尝试创建一个使用这个参数的spider类。</p>
<p>参数:</p>
<blockquote>
<ul>
<li><strong>crawler_or_spidercls</strong> (<a href="#">Crawler</a>实例, <a href="#">Spider</a>子类或字符串) – 已经在项目中创建了crawler，或者一个spider类或spider的名称来创建它</li>
<li><strong>args</strong> (列表) – 初始化spider的参数</li>
<li><strong>kwargs</strong> (字典) – 初始化spider的关键字参数</li>
</ul>
</blockquote>
</blockquote>
<p><code>crawlers</code></p>
<blockquote>
<p>由<a href="#">crawl()</a>开始并由该类管理的一组<a href="#">crawlers</a>。</p>
</blockquote>
<p><code>create_crawler(crawler_or_spidercls)</code></p>
<blockquote>
<p>返回<a href="#">Crawler</a>对象。</p>
<ul>
<li>如果<em>crawler_or_spidercls</em>是一个Crawler，它将按原样返回。</li>
<li>如果<em>crawler_or_spidercls</em>是Spider子类，则为它构造一个新的Crawler。</li>
<li>如果<em>crawler_or_spidercls</em>是一个字符串，这个函数会在一个Scrapy项目中找到一个具有这个名称的spider(使用spider loader)，然后为它创建一个Crawler实例。</li>
</ul>
</blockquote>
<p><code>join()</code></p>
<blockquote>
<p>返回一个延迟，当所有托管<a href="#">crawlers</a>完成执行时触发。</p>
</blockquote>
<p><code>start(stop_after_crawl=True)</code></p>
<blockquote>
<p>该方法启动一个Twisted <a href="https://twistedmatrix.com/documents/current/core/howto/reactor-basics.html">reactor</a>，其池大小用<a href="#">REACTOR_THREADPOOL_MAXSIZE</a>调整，并基于<a href="DNSCACHE_ENABLED">DNSCACHE_ENABLED</a>和<a href="#">DNSCACHE_SIZE</a>安装一个DNS缓存。</p>
<p>如果<em>stop_after_crawl</em>为True，则在所有crawler完成之后，使用<a href="#">join()</a>将停止reactor。</p>
<p>参数: </p>
<ul>
<li>stop_after_crawl (布尔类型) – 当所有crawler完毕时，停止或不停止reactor</li>
</ul>
</blockquote>
<p><code>stop()</code></p>
<blockquote>
<p>同时停止所有爬虫作业。</p>
<p>返回一个延迟，当它们都结束时将被触发。</p>
</blockquote>
<h2 id="settings-api">Settings API</h2>
<h4 id="scrapysettingssettings_priorities">scrapy.settings.SETTINGS_PRIORITIES</h4>
<p>一个字典，用于设置Scrapy中使用的默认设置优先级的键名和优先级级别。</p>
<p>每个item都定义了一个设置入口点，给它一个用于标识的代码名和一个整数优先级。在<a href="#">Settings</a>类中设置和检索值时，较大的优先级优先于较小的优先级。</p>
<pre><code class="python">SETTINGS_PRIORITIES = {
    'default': 0,
    'command': 10,
    'project': 20,
    'spider': 30,
    'cmdline': 40,
}
</code></pre>

<p>有关每个settings源的详细说明，请参阅:<a href="#">Settings</a>。</p>
<h4 id="scrapysettingsget_settings_prioritypriority">scrapy.settings.get_settings_priority(priority)</h4>
<p>小助手函数，它在<a href="#">SETTINGS_PRIORITIES</a>字典中中查找一个给定的字符串优先级，并返回它的数值，或直接返回一个给定的数值优先级。</p>
<h4 id="scrapysettingssettingsvaluesnone-priorityproject-class">scrapy.settings.Settings(values=None, priority='project')   这是一个类(class)</h4>
<p>基础: <a href="#">scrapy.settings.BaseSettings</a></p>
<p>该对象存储内部组件配置的Scrapy settings，可用于任何进一步的定制。</p>
<p>它是一个直接的子类，支持所有的<a href="#">BaseSettings</a>方法。此外，在实例化该类之后，新对象将具有内置settings引用中描述的全局默认设置。</p>
<h4 id="scrapysettingsbasesettingsvaluesnone-priorityproject-class">scrapy.settings.BaseSettings(values=None, priority='project')   这是一个类(class)</h4>
<blockquote>
<p>该类的实例的行为类似于字典，但是存储优先级和它们的<code>(key, value)</code>对，并且可以被冻结(即标记为不可变)。</p>
<p>键值入口可以在使用<code>values</code>参数进行初始化时传递，并且它们将采用<code>priority</code>级别(除非<code>values</code>已经是<a href="#">BaseSettings</a>的实例，在这种情况下将保留现有的priority级别)。如果<code>priority</code>参数是字符串，priority名称将在<a href="#">SETTINGS_PRIORITIES</a>中查询。否则，应该提供一个特定的整数。</p>
<p>一旦创建了对象，就可以使用<a href="#">set()</a>方法加载或更新新的settings，并且可以使用字典的方括号符号访问，或者使用实例的<a href="#">get()</a>方法及其值转换变体访问。当请求存储键时，将检索具有最高优先级的值。</p>
</blockquote>
<p><code>copy()</code></p>
<blockquote>
<p>对当前设置进行deep copy。</p>
<p>此方法返回<a href="#">Settings</a>类的一个新实例，该实例使用相同的值及其priority进行填充。</p>
<p>对新对象的修改不会反映在原始settings中。</p>
</blockquote>
<p><code>copy_to_dict()</code></p>
<blockquote>
<p>复制当前settings并转换为dict。</p>
<p>此方法返回一个新的字典，其中填充了与当前settings相同的值及其priority。</p>
<p>对返回的dict的修改不会反映在原始settings中。</p>
<p>例如，这种方法对于在Scrapy shell中print settings很有用。</p>
</blockquote>
<p><code>freeze()</code></p>
<blockquote>
<p>禁用对当前settings的进一步更改。</p>
<p>调用此方法后，settings的当前状态将成为不可变的。通过<a href="#">set()</a>方法和它的变体尝试更改值是不可能的，并且会收到警告。</p>
</blockquote>
<p><code>frozencopy()</code></p>
<blockquote>
<p>返回当前settings的不可变副本。</p>
<p><a href="#">copy()</a>返回的对象中的<a href="#">freeze()</a>调用的别名。</p>
</blockquote>
<p><code>get(name, default=None)</code></p>
<blockquote>
<p>获取不影响其原始类型的setting值。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting名字</li>
<li>default (任何) – 如果没有找到setting，则返回的值</li>
</ul>
</blockquote>
</blockquote>
<p><code>getbool(name, default=False)</code></p>
<blockquote>
<p>获取作为布尔值的setting值。</p>
<p><code>1</code>, <code>'1'</code>，True和<code>'True'</code>返回<code>True</code>, 当<code>0</code>, <code>'0'</code>, <code>False</code>, <code>'False'</code>和<code>None</code>返回<code>False</code></p>
<p>例如，通过设置为<code>'0'</code>的环境变量填充的设置在使用此方法时将返回<code>False</code>。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting name</li>
<li>default (任何) – 如果没有找到setting，则返回的值</li>
</ul>
</blockquote>
</blockquote>
<p><code>getdict(name, default=None)</code></p>
<blockquote>
<p>获取作为字典的setting值。如果setting的原始类型是字典，则返回字典的副本。如果它是一个字符串，它将作为JSON字典进行计算。如果它本身是一个<a href="#">BaseSettings</a>实例，那么它将被转换为一个字典，其中包含所有当前settings值，因为<a href="#">get()</a>会返回这些值，并且丢失所有关于priority(优先级)和mutability(可变性的信息)。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting name</li>
<li>default (任何) – 如果没有找到setting，则返回的值</li>
</ul>
</blockquote>
</blockquote>
<p><code>getfloat(name, default=0.0)</code></p>
<blockquote>
<p>获取作为int类型的setting值。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting名字</li>
<li>default (任何) – 如果没有找到setting，则返回的值</li>
</ul>
</blockquote>
</blockquote>
<p><code>getlist(name, default=None)</code></p>
<blockquote>
<p>以列表的形式获取setting值。如果setting原始类型为列表，则返回列表的副本。如果是字符串，它会被"，"分割。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting名字</li>
<li>default (任何) – 如果没有找到setting，则返回的值</li>
</ul>
</blockquote>
</blockquote>
<p><code>getpriority(name)</code></p>
<blockquote>
<p>返回当前setting的数值优先级值，如果给定<code>name</code>不存在，则返回<code>None</code>。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting名字</li>
</ul>
</blockquote>
</blockquote>
<p><code>getwithbase(name)</code></p>
<blockquote>
<p>获取类似于字典的setting及其对应的_BASE的组合。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – 类似于字典的setting名字</li>
</ul>
</blockquote>
</blockquote>
<p><code>maxpriority()</code></p>
<blockquote>
<p>返回所有设置中最高priority的数值，或者如果没有存储settings，则返回<a href="#">SETTINGS_PRIORITIES</a>中<code>default</code>值的数值。</p>
</blockquote>
<p><code>set(name, value, priority='project')</code></p>
<blockquote>
<p>存储具有给定priority的键/值属性。</p>
<p>在配置Crawler对象<em>之前</em>应该填充Settings(通过<a href="#">configure()</a>方法)，否则不会有任何效果。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>name (字符串) – setting名字</li>
<li>value (任何) – 与settings相关联的值</li>
<li>priority(字符串或整型) -settings的priority值。键应该是<a href="#">SETTINGS_PRIORITIES</a>或一个整型</li>
</ul>
</blockquote>
</blockquote>
<p><code>setmodule(module, priority='project')</code></p>
<blockquote>
<p>从具有给定priority的模块存储settings。</p>
<p>这是一个助手函数，它为<code>module</code>的每个全局声明的大写变量调用<a href="#">set()</a>，并提供<code>priority</code>。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>module (module对象或字符串) – module或module的路径</li>
<li>priority (字符串或整型) – settings的priority值, 键应该是<a href="#">SETTINGS_PRIORITIES</a>或一个整型</li>
</ul>
</blockquote>
</blockquote>
<p><code>update(values, priority='project')</code></p>
<blockquote>
<p>存储具有给定priority的键/值对。</p>
<p>这是一个助手函数，它为具有提供<code>priority</code>的每个item调用<a href="#">set()</a>。</p>
<p>如果<code>values</code>是一个字符串，则假定它是json编码的，并首先解析为具有<code>json.loads()</code>的dict。如果它是一个<a href="#">BaseSettings</a>实例，将使用每个键的priority，忽略<code>priority</code>参数。这允许用一个命令插入/更新具有不同priority的settings 。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>values (字典或字符串或<a href="#">BaseSettings</a>) – settings名称和值</li>
<li>priority (字符串或整型) – settings的priority。键应该是<a href="#">SETTINGS_PRIORITIES</a>或一个整型</li>
</ul>
</blockquote>
</blockquote>
<h2 id="spiderloader-api">SpiderLoader API</h2>
<h4 id="scrapyloaderspiderloader-class">scrapy.loader.SpiderLoader   这是一个类(class)</h4>
<blockquote>
<p>这个类负责检索和处理跨项目定义的spider类。</p>
<p>可以通过在<a href="#">SPIDER_LOADER_CLASS</a>项目setting中指定它们的路径来使用自定义的spider loaders。它们必须完全实现<code>scrapy.interfaces.ISpiderLoader</code>接口，以保证无错误的执行。</p>
<p><code>from_settings(settings)</code></p>
<blockquote>
<p>Scrapy使用这个类方法创建该类的实例。它与当前项目settings一起调用，它加载在<a href="#">SPIDER_MODULES</a> setting的模块中递归找到的spiders。</p>
<p>参数: </p>
<blockquote>
<ul>
<li>settings (<a href="#">Settings</a> 实例) – 项目settings</li>
</ul>
</blockquote>
</blockquote>
<p><code>load(spider_name)</code></p>
<blockquote>
<p>获取具有给定名称的Spider类。它将查找先前装载的spider类，查找具有<em>spider_name</em>的spider类，如果没有找到，则会引发一个KeyError。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>spider_name (字符串) – spider类名</li>
</ul>
</blockquote>
</blockquote>
<p><code>list()</code></p>
<blockquote>
<p>获取项目中可用的spider的名称。</p>
</blockquote>
<p><code>find_by_request(request)</code></p>
<blockquote>
<p>列出能够处理给定request的spider的名称。将尝试将request的url与spider的domains相匹配。</p>
<p>参数:</p>
<blockquote>
<p>request (<a href="#">Request</a> 实例) - 查询request</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="signals-api">Signals API(信号)</h2>
<h4 id="scrapysignalmanagersignalmanagersender95anonymous-class">scrapy.signalmanager.SignalManager(sender=_Anonymous)   这是一个类(class)</h4>
<blockquote>
<p><code>connect(receiver, signal, **kwargs)</code></p>
<blockquote>
<p>将 接收函数 连接到signal。</p>
<p>signal可以是任何对象，尽管Scrapy附带一些预定义的signal，这些signal在<a href="#">Signals</a>部分有文档说明。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>receiver (可调用的) – 要接收的函数</li>
<li>signal (对象) – 连接signal到..</li>
</ul>
</blockquote>
</blockquote>
<p><code>disconnect(receiver, signal, **kwargs)</code></p>
<blockquote>
<p>从signal中 中断 接收函数。这与<a href="#">connect()</a>方法的效果相反，而且参数是相同的。</p>
</blockquote>
<p><code>disconnect_all(signal, **kwargs)</code></p>
<blockquote>
<p>从给定signal中断开所有接收器。</p>
<p>参数:</p>
<blockquote>
<ul>
<li>signal (对象) – 从..信号中断开</li>
</ul>
</blockquote>
</blockquote>
<p><code>send_catch_log(signal, **kwargs)</code></p>
<blockquote>
<p>发送一个signal，捕获异常并log它们。</p>
<p>关键字参数传递给signal处理程序(通过<a href="#">connect()</a>方法连接)。</p>
</blockquote>
<p><code>send_catch_log_deferred(signal, **kwargs)</code></p>
<blockquote>
<p>与<a href="#">send_catch_log()</a>一样，但支持从signal处理程序返回<a href="https://twistedmatrix.com/documents/current/core/howto/defer.html">延迟</a>。</p>
<p>返回一个延迟，当所有signal处理程序延迟被触发时，该延迟被触发。发送一个signal，捕获异常并log它们。</p>
<p>关键字参数传递给signal处理程序(通过<a href="#">connect()</a>方法连接)。</p>
</blockquote>
</blockquote>
<h2 id="stats-collector-api">Stats Collector API</h2>
<p>在<a href="#">scrapy.statscollectors</a>模块下有几个Stats Collectors可用，它们都实现了<a href="#">StatsCollector</a>类定义的Stats Collector API(它们都从<a href="#">StatsCollector</a>类继承)。</p>
<h4 id="scrapystatscollectorsstatscollector-class">scrapy.statscollectors.StatsCollector   这是一个类(class)</h4>
<blockquote>
<p><code>get_value(key, default=None)</code></p>
<blockquote>
<p>返回给定stats键的值，如果不存在，则返回默认值。</p>
</blockquote>
<p><code>get_stats()</code></p>
<blockquote>
<p>从当前运行的spider获取所有stats。</p>
</blockquote>
<p><code>set_value(key, value)</code></p>
<blockquote>
<p>为给定的stats键设置给定的值。</p>
</blockquote>
<p><code>set_stats(stats)</code></p>
<blockquote>
<p>用<code>stats</code>参数中传递的dict覆盖当前的stats。</p>
</blockquote>
<p><code>inc_value(key, count=1, start=0)</code></p>
<blockquote>
<p>假设给定的起始值(未设置时)，将给定的stats键的值增加到给定的计数。</p>
</blockquote>
<p><code>max_value(key, value)</code></p>
<blockquote>
<p>仅当相同键的当前值低于值时，才为给定键设置给定值。如果给定键没有当前值，则总是设置该值。</p>
</blockquote>
<p><code>min_value(key, value)</code></p>
<blockquote>
<p>仅当相同键的当前值大于值时，才为给定键设置给定值。如果给定键没有当前值，则总是设置该值。</p>
</blockquote>
<p><code>clear_stats()</code></p>
<blockquote>
<p>清除所有stats。</p>
</blockquote>
<p><code>open_spider(spider)</code></p>
<blockquote>
<p>打开给定的spider以收集stats collection。</p>
</blockquote>
<p><code>close_spider(spider)</code></p>
<blockquote>
<p>关闭给定的spider。调用之后，就不能访问或收集更多特定的stats。</p>
</blockquote>
</blockquote>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../06-signals/" class="btn btn-neutral float-right" title="Signals(信号)">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../04-Extensions/" class="btn btn-neutral" title="Extensions(扩展)"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../04-Extensions/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../06-signals/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
