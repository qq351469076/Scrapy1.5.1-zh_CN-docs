<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="None">
  <meta name="author" content="孔祥旭">
  <link rel="shortcut icon" href="img/favicon.ico">
  <title>第一步 - Scrapy 1.5 中文文档</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="css/theme.css" type="text/css" />
  <link rel="stylesheet" href="css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u7b2c\u4e00\u6b65";
    var mkdocs_page_input_path = "index.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="js/jquery-2.1.1.min.js" defer></script>
  <script src="js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> Scrapy 1.5 中文文档</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1 current">
		
    <a class="current" href=".">第一步</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#_1">第一步</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#scrapy-15">Scrapy 1.5 中文文档</a></li>
        
            <li><a class="toctree-l3" href="#_2">获取帮助</a></li>
        
            <li><a class="toctree-l3" href="#_3">第一步</a></li>
        
            <li><a class="toctree-l3" href="#_6">基本概念</a></li>
        
            <li><a class="toctree-l3" href="#_8">内置服务</a></li>
        
            <li><a class="toctree-l3" href="#_12">解决具体问题</a></li>
        
            <li><a class="toctree-l3" href="#scrapy_2">Scrapy扩展</a></li>
        
            <li><a class="toctree-l3" href="#_23">其他的</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#scrapy_4">一眼了解Scrapy</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#spider">通过一个示例spider</a></li>
        
            <li><a class="toctree-l3" href="#_24">刚刚发生了什么?</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">Scrapy 1.5 中文文档</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>第一步</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="_1">第一步</h1>
<h2 id="scrapy-15">Scrapy 1.5 中文文档</h2>
<p>这个文档包含了所有关于Scrapy需要了解的内容</p>
<h2 id="_2">获取帮助</h2>
<p>有麻烦了么? 我们愿意提供帮助!</p>
<ul>
<li>尝试<a href="#">常见问题</a>-它有一些常见问题的答案。</li>
<li>请<a href="#">尝试索引</a>或<a href="#">模块索引</a>来寻找特定信息。</li>
<li>使用<a href="#">scrapy标签在StackOverflow</a>查询或搜索问题。</li>
<li>在<a href="#">reddit的Scrapy版块</a>中询问或搜索问题。</li>
<li>在<a href="#">scrapy用户邮件列表的档案</a>中搜索问题。</li>
<li>在<a href="#">scrapy IRC频道</a>搜索问题</li>
<li>报告scrapy出现的bug发送给<a href="https://github.com/scrapy/scrapy/issues">官方的问题跟踪器</a></li>
</ul>
<h2 id="_3">第一步</h2>
<h5 id="scrapy"><a href="#">快速理解Scrapy</a></h5>
<p>理解什么是Scrapy, 它能帮助你做什么</p>
<h5 id="_4"><a href="#">安装指南</a></h5>
<p>在你的电脑上安装Scrapy</p>
<h5 id="scrapy_1"><a href="#">Scrapy教程</a></h5>
<p>编写你的第一个Scrapy程序</p>
<h5 id="_5"><a href="#">例子</a></h5>
<p>通过一个写好的Scrapy程序来了解更多Scrapy的知识</p>
<h2 id="_6">基本概念</h2>
<h5 id="_7"><a href="#">命令行工具</a></h5>
<p>了解用于管理Scrapy项目的命令行工具。</p>
<h5 id="spiders"><a href="#">Spiders(爬虫主文件)</a></h5>
<p>编写你抓取网站的规则</p>
<h5 id="selectors"><a href="#">Selectors(选择器)</a></h5>
<p>使用XPATH从网站上提取数据</p>
<h5 id="scrapy-shell"><a href="">Scrapy shell</a></h5>
<p>在交互式环境中测试提取代码</p>
<h5 id="items"><a href="#">Items</a></h5>
<p>定义你想要获取数据</p>
<h5 id="item-loaders"><a href="#">Item Loaders</a></h5>
<p>用提取的数据填充items</p>
<h5 id="item-pipeline"><a href="#">Item Pipeline(数据管道)</a></h5>
<p>后期处理或将你抓取的数据保存起来</p>
<h5 id="feed-exports"><a href="#">Feed exports</a></h5>
<p>使用不同的格式和存储来输出抓取的数据。</p>
<h5 id="requests-and-responses"><a href="#">Requests and Responses(请求和响应)</a></h5>
<p>了解用于表示HTTP请求和响应的类。</p>
<h5 id="link-extractors"><a href="#">Link Extractors(链接抽取器)</a></h5>
<p>一个很方便的类用于从页面中提取链接</p>
<h5 id="settings"><a href="#">Settings(设置)</a></h5>
<p>了解如何配置Scrapy并查看所有<a href="#">可用的设置</a>。</p>
<h2 id="_8">内置服务</h2>
<h5 id="_9"><a href="#">日志模块</a></h5>
<p>了解如何在Scrapy上使用Python的内置日志模块。</p>
<h5 id="_10"><a href="#">状态收集</a></h5>
<p>收集关于抓取爬虫的统计数据。</p>
<h5 id="_11"><a href="#">邮件模块</a></h5>
<p>当某些事件发生时发送电子邮件通知。</p>
<h5 id="telnet"><a href="#">Telnet控制台</a></h5>
<p>使用内置的Python控制台检查正在运行的爬虫程序。</p>
<h5 id="web"><a href="#">Web服务</a></h5>
<p>使用web服务监视和控制爬虫程序。</p>
<h2 id="_12">解决具体问题</h2>
<h5 id="_13"><a href="#">常见问题</a></h5>
<p>找出最常见问题的答案。</p>
<h5 id="spiders_1"><a href="#">调试Spiders</a></h5>
<p>了解如何调试您的spiders的常见问题。</p>
<h5 id="spiders-contracts"><a href="#">Spiders Contracts</a></h5>
<p>学习如何使用合同测试您的spiders。</p>
<h5 id="_14"><a href="#">一般做法</a></h5>
<p>熟悉一些常见的技巧。</p>
<h5 id="_15"><a href="#">大规模爬取</a></h5>
<p>对并行抓取大量网站的Scrapy进行优化。</p>
<h5 id="firefox"><a href="#">使用Firefox抓取</a></h5>
<p>学习如何用Firefox进行抓取并附加一些有用的附加组件。</p>
<h5 id="firebug"><a href="#">使用Firebug抓取</a></h5>
<p>学习如何有效地使用Firebug。</p>
<h5 id="_16"><a href="#">调试内存泄漏</a></h5>
<p>了解如何在爬虫程序中查找和清除内存泄漏。</p>
<h5 id="_17"><a href="#">下载或处理文件和图像</a></h5>
<p>从Scrapy items里下载文件或图像</p>
<h5 id="_18"><a href="#">部署爬虫</a></h5>
<p>部署您的Scrapy爬虫并且放在远程服务器</p>
<h5 id="_19"><a href="#">自动节流阀扩展</a></h5>
<p>根据负载动态调整抓取速度。</p>
<h5 id="benchmarking"><a href="#">benchmarking</a></h5>
<p>检查一下Scrapy在硬件上的功能。</p>
<h5 id="jobs"><a href="#">Jobs: 暂停和恢复爬取</a></h5>
<p>学习如何暂停和恢复爬行大型蜘蛛。</p>
<h2 id="scrapy_2">Scrapy扩展</h2>
<h5 id="_20"><a href="#">结构概述</a></h5>
<p>理解Scrapy架构。</p>
<h5 id="downloader-middleware"><a href="#">Downloader Middleware(下载器中间件)</a></h5>
<p>自定义页面如何被请求和下载。</p>
<h5 id="spider-middleware"><a href="#">Spider Middleware(爬虫中间件)</a></h5>
<p>自定义spiders的输入和输出。</p>
<h5 id="_21"><a href="#">扩展</a></h5>
<p>使用自定义功能扩展Scrapy</p>
<h5 id="api"><a href="#">核心API</a></h5>
<p>在扩展和中间件上使用它来扩展Scrapy的功能</p>
<h5 id="_22"><a href="#">信号</a></h5>
<p>查看所有可用的信号以及如何使用它们。</p>
<h5 id="item-exporters"><a href="#">Item Exporters</a></h5>
<p>快速导出你抓取的数据到一个文件(XML, CSV，等等)。</p>
<h2 id="_23">其他的</h2>
<h5 id="151"><a href="#">发行说明</a>  (此文档从1.5.1版本开始, 以前版本不在做介绍)</h5>
<p>看看最近的Scrapy有什么变化。</p>
<h5 id="scrapy_3"><a href="#">为Scrapy做贡献</a></h5>
<p>学习如何为Scrapy项目贡献力量。</p>
<h5 id="api_1"><a href="#">版本控制和API的稳定性</a></h5>
<p>了解Scrapy版本控制和API稳定性。</p>
<h1 id="scrapy_4">一眼了解Scrapy</h1>
<p>Scrapy是一个用于抓取web站点和提取结构化数据的应用程序框架，可用于各种有用的应用程序，如数据挖掘、信息处理或历史档案。</p>
<p>尽管Scrapy最初是为web抓取而设计的，但它还可以使用api(如Amazon Associates web服务)或作为通用web爬虫程序来提取数据。</p>
<h2 id="spider">通过一个示例spider</h2>
<p>为了向您展示Scrapy带来了什么，我们将介绍一个使用最简单的方式运行Spider的Scrapy爬虫示例。</p>
<p>下面是一个爬虫的代码，它会从http://quotes.toscrape.com网站上的著名引文中抓取引文，然后进行向后翻页:</p>
<pre><code>import scrapy


class QuotesSpider(scrapy.Spider):
    name = "quotes" # 爬虫项目的名字
    start_urls = [
        'http://quotes.toscrape.com/tag/humor/',    # 最开始要抓取的页面
    ]

    def parse(self, response):  # 解析要抓取的页面
        for quote in response.css('div.quote'): # 选择器选择要抓取的节点
            yield {
                'text': quote.css('span.text::text').extract_first(),   # 获取列表里面第一个, 如果没有会自动捕获异常
                'author': quote.xpath('span/small/text()').extract_first(),
            }

        next_page = response.css('li.next a::attr("href")').extract_first() # 找到下一页的节点
        if next_page is not None:   # 如果有下一页的节点
            yield response.follow(next_page, self.parse)    # 继续通过parse函数进行解析
</code></pre>
<p>将其放入文本文件中，将其命名为<code>quotes_spider.py</code>并使用<code>runspider</code>命令运行爬虫:</p>
<pre><code>scrapy runspider quotes_spider.py -o quotes.json
</code></pre>
<p>当这结束时，你会在<code>quotes.json</code>文件得到JSON格式列表，包含文本和作者，如下所示(为了更好的可读性，这里重新格式化):</p>
<pre><code>[{
"author": "Jane Austen",
"text": "\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d"
},
{
    "author": "Groucho Marx",
    "text": "\u201cOutside of a dog, a book is man's best friend. Inside of a dog it's too dark to read.\u201d"
},
{
    "author": "Steve Martin",
    "text": "\u201cA day without sunshine is like, you know, night.\u201d"
},
...]
</code></pre>
<h2 id="_24">刚刚发生了什么?</h2>
<p>当你运行命令 <code>scrapy runspider quotes_spider.py</code>, Scrapy在里面找到了文件名为quotes_spider的爬虫, 然后让它通过爬虫引擎运行。</p>
<p>爬虫通过向<code>start_urls</code>属性中定义的URL发出请求(在本例中，仅为列表中的引号URL)并调用默认回调方法<code>parse</code>函数，将Response对象作为参数传递。
在<code>parse</code>方法回调中，我们使用CSS选择器循环引用元素，使用提取的文本和作者生成Python词典，查找到下一页的链接，并使用与回调相同的<code>parse</code>方法调度另一个请求。
在这里，您会注意到Scrapy的一个主要优点:requests是异步调度和处理的。 这意味着Scrapy不需要等待上一个请求被完成和处理，它可以同时发送多个请求或做其他事情。这也意味着，即使某些请求失败或在处理时发生错误，其他请求也可以继续运行。</p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme.js" defer></script>
      <script src="search/main.js" defer></script>

</body>
</html>

<!--
MkDocs version : 1.0.3
Build Date UTC : 2018-08-30 09:00:52
-->
